{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8a2cd0b",
   "metadata": {},
   "source": [
    "# # China Real Estate Demand Prediction — Pipeline Skeleton\n",
    "#\n",
    "# **Last generated:** 2025-10-06 07:47 UTC\n",
    "#\n",
    "# This notebook/script is a lean, safe baseline skeleton tailored to the Kaggle\n",
    "# competition *\"Real Estate Demand Prediction\"*.\n",
    "#\n",
    "# ### What you get\n",
    "# - Robust **IO setup** targeting Kaggle input paths\n",
    "# - **Custom competition metric** (two-stage MAPE-based)\n",
    "# - **Leakage-safe** rolling time-grouped cross-validation\n",
    "# - Minimal **feature factory** with lags/rollings (extend here)\n",
    "# - **Naïve** baseline (strong Stage-1 shield)\n",
    "# - **LightGBM Tweedie** model scaffold + optional XGB/CatBoost hooks\n",
    "# - **Blending + clipping** for metric safety\n",
    "# - **Submission writer** preserving `test.csv` row order\n",
    "#\n",
    "# > Notes:\n",
    "# > - Extend features in the marked sections. Keep temporal embargo ≥ max lag.\n",
    "# > - If the official epsilon/edge-case handling differs, update the metric function accordingly.\n",
    "#\n",
    "# ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "973a7668",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, gc, sys, math, warnings, itertools, json\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Tuple, Dict, Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "try:\n",
    "    import lightgbm as lgb\n",
    "except Exception as e:\n",
    "    lgb = None\n",
    "\n",
    "try:\n",
    "    import xgboost as xgb\n",
    "except Exception as e:\n",
    "    xgb = None\n",
    "\n",
    "try:\n",
    "    from catboost import CatBoostRegressor, Pool as CatPool\n",
    "except Exception as e:\n",
    "    CatBoostRegressor, CatPool = None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "022293cd",
   "metadata": {
    "tags": [
     "Config"
    ]
   },
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    seed = 42\n",
    "    n_folds = 5\n",
    "    embargo_months = 3             # >= max lag window used in features\n",
    "    use_target_lags = True         # if True, recursive inference to populate target lags\n",
    "    use_tweedie = True             # main LightGBM objective\n",
    "    lgb_params = dict(\n",
    "        objective = \"tweedie\",\n",
    "        tweedie_variance_power = 1.3,  # tune 1.3~1.7\n",
    "        metric = \"mae\",\n",
    "        num_leaves = 63,\n",
    "        max_depth = 8,\n",
    "        learning_rate = 0.05,\n",
    "        feature_fraction = 0.6,\n",
    "        bagging_fraction = 0.8,\n",
    "        bagging_freq = 1,\n",
    "        min_data_in_leaf = 128,\n",
    "        lambda_l1 = 0.0,\n",
    "        lambda_l2 = 5.0,\n",
    "        n_estimators = 3000,\n",
    "        verbose = -1,\n",
    "        random_state = seed\n",
    "    )\n",
    "\n",
    "    data_dir = \"/kaggle/input/china-real-estate-demand-prediction\"\n",
    "    out_dir  = \"/kaggle/working\"\n",
    "    target_col = \"amount_new_house_transactions\"  # train target column name\n",
    "    id_col     = \"id\"\n",
    "    month_col  = \"month\"\n",
    "    sector_col = \"sector\"\n",
    "    sector_int_col = \"sector_int\"\n",
    "    # files\n",
    "    files = dict(\n",
    "        new_house=\"train/new_house_transactions.csv\",\n",
    "        new_house_nb=\"train/new_house_transactions_nearby_sectors.csv\",\n",
    "        pre_owned=\"train/pre_owned_house_transactions.csv\",\n",
    "        pre_owned_nb=\"train/pre_owned_house_transactions_nearby_sectors.csv\",\n",
    "        land=\"train/land_transactions.csv\",\n",
    "        land_nb=\"train/land_transactions_nearby_sectors.csv\",\n",
    "        poi=\"train/sector_POI.csv\",\n",
    "        search=\"train/city_search_index.csv\",\n",
    "        city=\"train/city_indexes.csv\",\n",
    "        test=\"test.csv\",\n",
    "        sample=\"sample_submission.csv\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569e02ce",
   "metadata": {
    "tags": [
     "Utils"
    ]
   },
   "outputs": [],
   "source": [
    "def set_seed(seed:int=42):\n",
    "    import random\n",
    "    random.seed(seed); np.random.seed(seed)\n",
    "\n",
    "def month_to_timestamp(m: str) -> pd.Timestamp:\n",
    "    \"\"\"\n",
    "    Parse month strings like '2019 Jan' to Timestamp at month-end.\n",
    "    \"\"\"\n",
    "    # there might be localized month abbreviations; try a few formats\n",
    "    for fmt in [\"%Y %b\", \"%Y-%m\", \"%b %Y\"]:\n",
    "        try:\n",
    "            return pd.to_datetime(m, format=fmt) + pd.offsets.MonthEnd(0)\n",
    "        except Exception:\n",
    "            pass\n",
    "    # fallback\n",
    "    return pd.to_datetime(m) + pd.offsets.MonthEnd(0)\n",
    "\n",
    "def parse_sector(val) -> int:\n",
    "    \"\"\"\n",
    "    Convert 'sector 3' or 3 -> int 3.\n",
    "    \"\"\"\n",
    "    if pd.isna(val): return np.int16(-1)\n",
    "    if isinstance(val, (int, np.integer)): return int(val)\n",
    "    s = str(val).strip().lower()\n",
    "    for token in [\"sector\", \"_\", \"-\"]:\n",
    "        s = s.replace(token, \" \")\n",
    "    parts = s.split()\n",
    "    nums = [p for p in parts if p.isdigit()]\n",
    "    return int(nums[-1]) if nums else int(float(parts[-1])) if parts else -1\n",
    "\n",
    "def ensure_cols(df: pd.DataFrame, cols: List[str]):\n",
    "    for c in cols:\n",
    "        if c not in df.columns:\n",
    "            df[c] = np.nan\n",
    "    return df\n",
    "\n",
    "def reduce_mem(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    for col in df.columns:\n",
    "        if pd.api.types.is_float_dtype(df[col]):\n",
    "            df[col] = pd.to_numeric(df[col], downcast=\"float\")\n",
    "        elif pd.api.types.is_integer_dtype(df[col]):\n",
    "            df[col] = pd.to_numeric(df[col], downcast=\"integer\")\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2002ee5",
   "metadata": {
    "tags": [
     "I/O"
    ]
   },
   "outputs": [],
   "source": [
    "def load_csv(path: str, dtype=None) -> pd.DataFrame:\n",
    "    full = os.path.join(CFG.data_dir, path)\n",
    "    if not os.path.exists(full):\n",
    "        print(f\"[WARN] Missing file: {full}\")\n",
    "        return pd.DataFrame()\n",
    "    df = pd.read_csv(full, dtype=dtype)\n",
    "    return df\n",
    "\n",
    "def load_all():\n",
    "    dfs = {}\n",
    "    for k, rel in CFG.files.items():\n",
    "        dfs[k] = load_csv(rel)\n",
    "    return dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8bfcf6a",
   "metadata": {
    "tags": [
     "Data Normalization"
    ]
   },
   "outputs": [],
   "source": [
    "def normalize_month_sector(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Standardize month -> Timestamp month-end; sector -> int.\n",
    "    Some CSVs might miss either column or encode differently; handle robustly.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    if CFG.month_col in df.columns:\n",
    "        df[CFG.month_col] = df[CFG.month_col].astype(str).str.strip().apply(month_to_timestamp)\n",
    "    else:\n",
    "        # Try to split from 'id' pattern 'YYYY Mon_sector n'\n",
    "        if CFG.id_col in df.columns:\n",
    "            tmp = df[CFG.id_col].astype(str).str.split(\"_sector\", n=1, expand=True)\n",
    "            df[CFG.month_col] = tmp[0].str.strip().apply(month_to_timestamp)\n",
    "            df[CFG.sector_col] = \"sector \" + tmp[1].str.strip()\n",
    "    if CFG.sector_col in df.columns:\n",
    "        df[CFG.sector_int_col] = df[CFG.sector_col].apply(parse_sector).astype(\"int16\")\n",
    "    else:\n",
    "        # try parse from 'month' if it accidentally concatenated\n",
    "        # e.g. '2019 Jan_sector 3' stored under month\n",
    "        mask = df[CFG.month_col].astype(str).str.contains(\"sector\", case=False, na=False)\n",
    "        if mask.any():\n",
    "            ss = df.loc[mask, CFG.month_col].astype(str)\n",
    "            # split\n",
    "            mm = ss.str.split(\"_sector\", n=1, expand=True)\n",
    "            df.loc[mask, CFG.month_col] = mm[0].apply(month_to_timestamp)\n",
    "            df.loc[mask, CFG.sector_int_col] = mm[1].apply(parse_sector).astype(\"int16\")\n",
    "        else:\n",
    "            df[CFG.sector_int_col] = -1\n",
    "    return df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
